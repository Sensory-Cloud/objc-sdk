//
//  VoiceSynthesisExampleViewController.m
//  objc-sdk-test-app
//
//  Created by Niles Hacking on 3/8/23.
//  Copyright Â© 2023 Niles Hacking. All rights reserved.
//

#import "VoiceSynthesisExampleViewController.h"
#import <SensoryCloud/SensoryCloud-umbrella.h>

@interface VoiceSynthesisExampleViewController ()
@property SENAudioService* audioService;
@property NSMutableData* audioFile;
@end

@implementation VoiceSynthesisExampleViewController

@synthesize dispatchQueue;

- (void) viewDidLoad {
    [super viewDidLoad];

    [self startAudioExample];
}

- (void)startAudioExample {
    // Initialize audio service
    // NOTE: In a production app, the same tokenManager instance should be
    //       shared between every initialized service
    SENKeychainManager* credentialStore = [SENKeychainManager alloc];
    SENOAuthService* oauthService = [[SENOAuthService alloc] init: credentialStore];
    SENTokenManager* tokenManager = [[SENTokenManager alloc] init: oauthService];
    SENAudioService* audioService = [[SENAudioService alloc] init: tokenManager];
    self.audioService = audioService;

    // Setup a dispatch queue that will receive updates from the GRPC stream
    dispatch_queue_attr_t qos = dispatch_queue_attr_make_with_qos_class(DISPATCH_QUEUE_SERIAL, QOS_CLASS_USER_INTERACTIVE, -1);
    dispatchQueue = dispatch_queue_create("GRPCStreamingQueue", qos);

    // Create the configuration object for audio transcription
    // Available models can be received from the [audioService getModels:] call
    SENGAVoiceSynthesisConfig* config = [SENGAVoiceSynthesisConfig message];
    config.modelName = @"text_to_spectrogram_donna_en-us";
    config.sampleRateHertz = 16000;
    NSString* phrase = @"Phrase to synthesize speech for.";

    // Initialize the audio file to an empty data stream
    [self setAudioFile: [NSMutableData dataWithLength:0]];

    // Open a GRPC stream for speech synthesis
    [audioService synthesizeSpeech:phrase config:config handler:self];
}

// GRPCProtoResponseHandler protocol conformance, will be called with every response from the server
- (void)didReceiveProtoMessage:(GPBMessage *)message {
    // Cast the server response to the proper type
    SENGASynthesizeSpeechResponse* response = (SENGASynthesizeSpeechResponse*)message;
    if (response == nil) {
        return;
    }

    if (response.config) {
        // The first response from the server will contain a config message with formatting information
        // on the audio file it will stream down
    } else {
        // All subsequent messages will contain audio content
        // concatenating all of the audio content messages together will result in a final WAV file
        [[self audioFile] appendData:response.audioContent];
    }
}

// GRPCProtoResponseHandler protocol conformance, will be called once the stream is closed
// Any errors generated by the stream will also be sent to this function
- (void)didCloseWithTrailingMetadata:(NSDictionary *)trailingMetadata error:(NSError *)error {
    // Handle any errors that were generated
    if (error != nil) {
        NSLog(@"GRPC stream closed with error: %@", error.description);
        return;
    }

    // The server will automatically close the GRPC stream once it has finished streaming down the audio file
    // The complete audio file is now stored in `self.audioFile`
    NSLog(@"Speech successfully synthesized");
}

@end

